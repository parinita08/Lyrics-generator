{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaylorSwift Lyrics Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parinita08/Lyrics-generator/blob/master/TaylorSwift_Lyrics_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5jgH2FZbGB",
        "colab_type": "text"
      },
      "source": [
        "# **Taylor Swift Lyrics Generator**\n",
        "![](https://cdn-images-1.medium.com/max/1800/1*VSXmKKJJZFlUVVZWBwbXVg.jpeg)\n",
        "\n",
        "A few days ago, I started to learn LSTM RNN (Long Short Term Memory Recurrent Neural Networks), and I thought that it would be a good idea if I make a project using it.\n",
        "\n",
        "There is a multitude of applications of LSTM RNN, I decided to go with natural language generation because it will be a good opportunity to learn how to process text data, and it will be entertaining to see texts generated by neural networks, so I got this idea about generating Taylor Swift lyrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5iAhbcOdsrX",
        "colab_type": "text"
      },
      "source": [
        "## **What is LSTM Recurrent Neural Networks ?**\n",
        "If you don't know, LSTM recurrent neural networks are networks with loops in them, allowing information to persist, and they have a special type of nodes called LSTM(Long Short Term Memory).\n",
        "\n",
        "LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
        "If you want to know more about  LSTM Recurrent Neural Networks visit :\n",
        "[Understanding LSTM Networks](https://goo.gl/dgmxQm) or [Long short-term memoryt](https://goo.gl/Dc7kHF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7KxCwI0ewIN",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Recurrent Neural Networks Applications \n",
        "LSTM Recurrent Neural Networks are used in many applicattions , the following are the most popular ones :\n",
        "\n",
        "\n",
        "\n",
        "*   Language modeling\n",
        "*   Text classification\n",
        "*   Dialog systems\n",
        "*   **Natural language generation**\n",
        "\n",
        "[More applications](https://goo.gl/eT3bMm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiAiWbbKjx2v",
        "colab_type": "text"
      },
      "source": [
        "Now, after we learned some essential information about LSTM and RNN , we will start implementing the idea (Taylor Swift Lyrics Generator) \n",
        "\n",
        "I will use two ways to build the model :\n",
        "* From scratch\n",
        "* Using a Python module called [textgenrnn](https://goo.gl/E7szXj)\n",
        "\n",
        "## Process The Dataset \n",
        "To train the LSTM model we need a dataset of Taylor songs' lyrics.\n",
        "After searching for it, I found [this great dataset](https://goo.gl/3oUpMG) in Kaggle .\n",
        "\n",
        "**Let's take a look at it :**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_K2b3bUl824",
        "colab_type": "text"
      },
      "source": [
        "first, import all the needed libraries for our project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coOsymS4l3Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d87T5nx4mlYP",
        "colab_type": "text"
      },
      "source": [
        "**Load the dataset :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlevTCJ4mjj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the dataset\n",
        "dataset = pd.read_csv('taylor_swift_lyrics.csv', encoding = \"latin1\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF7rXKwdnAd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "9737e885-083e-4b26-d2f4-45911acc9c8d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>track_title</th>\n",
              "      <th>track_n</th>\n",
              "      <th>lyric</th>\n",
              "      <th>line</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>He said the way my blue eyes shined</td>\n",
              "      <td>1</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>Put those Georgia stars to shame that night</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>I said, \"That's a lie\"</td>\n",
              "      <td>3</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>Just a boy in a Chevy truck</td>\n",
              "      <td>4</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>That had a tendency of gettin' stuck</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         artist         album  ... line  year\n",
              "0  Taylor Swift  Taylor Swift  ...    1  2006\n",
              "1  Taylor Swift  Taylor Swift  ...    2  2006\n",
              "2  Taylor Swift  Taylor Swift  ...    3  2006\n",
              "3  Taylor Swift  Taylor Swift  ...    4  2006\n",
              "4  Taylor Swift  Taylor Swift  ...    5  2006\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET89hoHGnHz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "de0438f2-7204-4ddb-c350-959eba007b71"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_n</th>\n",
              "      <th>line</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4862.000000</td>\n",
              "      <td>4862.000000</td>\n",
              "      <td>4862.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.216989</td>\n",
              "      <td>28.426573</td>\n",
              "      <td>2011.882764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.696379</td>\n",
              "      <td>18.343649</td>\n",
              "      <td>3.571447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2012.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           track_n         line         year\n",
              "count  4862.000000  4862.000000  4862.000000\n",
              "mean      8.216989    28.426573  2011.882764\n",
              "std       4.696379    18.343649     3.571447\n",
              "min       1.000000     1.000000  2006.000000\n",
              "25%       4.000000    13.000000  2010.000000\n",
              "50%       8.000000    26.000000  2012.000000\n",
              "75%      12.000000    41.000000  2014.000000\n",
              "max      19.000000   101.000000  2017.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeN5LhosnYD2",
        "colab_type": "text"
      },
      "source": [
        "From what we see , we need to concatenate the lines of each song to get each song by its own in one string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DFbVyycoFek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processFirstLine(lyrics, songID, songName, row):\n",
        "    lyrics.append(row['lyric'] + '\\n')\n",
        "    songID.append( row['year']*100+ row['track_n'])\n",
        "    songName.append(row['track_title'])\n",
        "    return lyrics,songID,songName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jTFUaamn19J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define empty lists for the lyrics , songID , songName \n",
        "lyrics = []\n",
        "songID = []\n",
        "songName = []\n",
        "\n",
        "# songNumber indicates the song number in the dataset\n",
        "songNumber = 1\n",
        "\n",
        "# i indicates the song number\n",
        "i = 0\n",
        "isFirstLine = True\n",
        "\n",
        "# Iterate through every lyrics line and join them together for each song independently \n",
        "for index,row in dataset.iterrows():\n",
        "    if(songNumber == row['track_n']):\n",
        "        if (isFirstLine):\n",
        "            lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "            isFirstLine = False\n",
        "        else :\n",
        "            #if we still in the same song , keep joining the lyrics lines    \n",
        "            lyrics[i] +=  row['lyric'] + '\\n'\n",
        "    #When it's done joining a song's lyrics lines , go to the next song :    \n",
        "    else :\n",
        "        lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "        songNumber = row['track_n']\n",
        "        i+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lEEwMvhpZ_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define a new pandas DataFrame to save songID , songName , Lyrics in it to use them later\n",
        "lyrics_data = pd.DataFrame({'songID':songID, 'songName':songName, 'lyrics':lyrics })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4CJdW-2pvHU",
        "colab_type": "text"
      },
      "source": [
        "Now save the lyrics in a text file to use it in the LSTM RNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N48sFRVHqFpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Lyrics in .txt file\n",
        "with open('lyricsText.txt', 'w',encoding=\"utf-8\") as filehandle:  \n",
        "    for listitem in lyrics:\n",
        "        filehandle.write('%s\\n' % listitem)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Dii_ZiqYlf",
        "colab_type": "text"
      },
      "source": [
        "After getting the wanted data from the dataset , we need to preprocess it.\n",
        "\n",
        "## Preprocessing The Lyrics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBR3GAjDQ_nL",
        "colab_type": "text"
      },
      "source": [
        "### 1- Convert the lyrics to lowercase :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVOSN8qIqz0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset and convert it to lowercase :\n",
        "textFileName = 'lyricsText.txt'\n",
        "raw_text = open(textFileName, encoding = 'UTF-8').read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4wKS9n5rpNg",
        "colab_type": "text"
      },
      "source": [
        "### 2- Mapping characters :\n",
        " Make two dictionaries , one to convert chars to ints , the other to convert ints back to chars : \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jafC0WcvsA4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping chars to ints :\n",
        "chars = sorted(list(set(raw_text)))\n",
        "int_chars = dict((i, c) for i, c in enumerate(chars))\n",
        "chars_int = dict((i, c) for c, i in enumerate(chars))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsWUvqD0sGsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of chars and vocab in our text :\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSItHMeqsMyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d676ec06-2585-4d1d-dba7-a045ad06bfdc"
      },
      "source": [
        "print('Total Characters : ' , n_chars) # number of all the characters in lyricsText.txt\n",
        "print('Total Vocab : ', n_vocab) # number of unique characters\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters :  173698\n",
            "Total Vocab :  58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErC8jLlDsxpH",
        "colab_type": "text"
      },
      "source": [
        "### 3- Make samples and labels :\n",
        "Make samples and labels to feed the LSTM RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7vPB3K6s-6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57515828-d043-418e-a8ba-c60c62672d36"
      },
      "source": [
        "# process the dataset:\n",
        "seq_len = 100\n",
        "data_X = []\n",
        "data_y = []\n",
        "\n",
        "for i in range(0, n_chars - seq_len, 1):\n",
        "    # Input Sequeance(will be used as samples)\n",
        "    seq_in  = raw_text[i:i+seq_len]\n",
        "    # Output sequence (will be used as target)\n",
        "    seq_out = raw_text[i + seq_len]\n",
        "    # Store samples in data_X\n",
        "    data_X.append([chars_int[char] for char in seq_in])\n",
        "    # Store targets in data_y\n",
        "    data_y.append(chars_int[seq_out])\n",
        "n_patterns = len(data_X)\n",
        "print( 'Total Patterns : ', n_patterns)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns :  173598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHF-E1QLuAf6",
        "colab_type": "text"
      },
      "source": [
        "### 4- Prepare the samples and labels :\n",
        "prepare the samples and labels to be ready to go into our model.\n",
        "* Reshape the samples\n",
        "* Normalize them\n",
        "* One hot encode the output targets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HL0q0DouKei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape X to be suitable to go into LSTM RNN :\n",
        "X = np.reshape(data_X , (n_patterns, seq_len, 1))\n",
        "# Normalizing input data :\n",
        "X = X/ float(n_vocab)\n",
        "# One hot encode the output targets :\n",
        "y = np_utils.to_categorical(data_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB9FHOuWzSMz",
        "colab_type": "text"
      },
      "source": [
        "After we finished processing the dataset , we will start building our LSTM RNN model .\n",
        "\n",
        "## Building The Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwg_rARt92L7",
        "colab_type": "text"
      },
      "source": [
        "## First way : From Scratch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbVsgyoj0R9G",
        "colab_type": "text"
      },
      "source": [
        "We will start by determining how many layers our model will has , and how many nodes each layer will has :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEBOjT8b0puT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_layer_num = 4 # number of LSTM layers\n",
        "layer_size = [256,256,256,256] # number of nodes in each layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaZgebyX0_DK",
        "colab_type": "text"
      },
      "source": [
        "Define a sequential model :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VoVZqCY1GlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1qmHybP50Mf",
        "colab_type": "text"
      },
      "source": [
        "### LSTM layer VS CuDNNLSTM layer \n",
        "The main difference is that LSTM uses the CPU and CuDNNLSTM uses the GPU , that's why CuDNNLSTM is much faster than LSTM , it is x15 faster.\n",
        "\n",
        "This is the reason that made me use CuDNNLTSM instead of LSTM .\n",
        "\n",
        "**Note :** make sure to change the runtime setting of colab to use its GPU ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5q0sEfv1IJg",
        "colab_type": "text"
      },
      "source": [
        "Add an input layer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBCy2aCI1NEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(layer_size[0], input_shape =(X.shape[1], X.shape[2]), return_sequences = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQE1EYX1TLD",
        "colab_type": "text"
      },
      "source": [
        "Add some hidden layers : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CngOC8xX1YcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,LSTM_layer_num) :\n",
        "    model.add(LSTM(layer_size[i], return_sequences=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc7Rd3WE1hTJ",
        "colab_type": "text"
      },
      "source": [
        "Flatten the data that is coming from the last hidden layer to input it to the output layer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZvmlrtO1tkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWlyuZM91yBt",
        "colab_type": "text"
      },
      "source": [
        "Add an output layer and define its activation function to be **'softmax'** \n",
        "\n",
        "and then compile the model with the next params :\n",
        "*  loss = 'categorical_crossentropy'\n",
        "*  optimizer = 'adam'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuaTsnQa1wSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bBWrlrV5EA1",
        "colab_type": "text"
      },
      "source": [
        "Print a summary of the model to see some details :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0_EwdN65L94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "092de0f4-2940-4bcd-963c-ae12a72553c0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 58)                1484858   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 58)                0         \n",
            "=================================================================\n",
            "Total params: 3,324,986\n",
            "Trainable params: 3,324,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKtPQlVW2fwm",
        "colab_type": "text"
      },
      "source": [
        "After we defined the model , we will define the needed callbacks.\n",
        "\n",
        "### What is a callback ?\n",
        "A callback is a function that is called after every epoch\n",
        "\n",
        "in our case we will call the checkpoint callback , what a checkpoint callback does is saving the weights of the model every time the model gets better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9agmjvU3gNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure the checkpoint :\n",
        "checkpoint_name = 'Weights-LSTM-improvement-{epoch:03d}-{loss:.5f}-bigger.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='loss', verbose = 1, save_best_only = True, mode ='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G3g4N7A3iTo",
        "colab_type": "text"
      },
      "source": [
        "## Training \n",
        "A model can't do a thing if it did not train.\n",
        "\n",
        "As they say **\"No train no gain \"**\n",
        "\n",
        "Feel free to tweak `model_params` to get a better model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a95hUKQf4OnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "899d08be-2b87-439d-e925-de8c78899539"
      },
      "source": [
        "# Fit the model :\n",
        "model_params = {'epochs':30,\n",
        "                'batch_size':128,\n",
        "                'callbacks':callbacks_list,\n",
        "                'verbose':1,\n",
        "                'validation_split':0.2,\n",
        "                'validation_data':None,\n",
        "                'shuffle': True,\n",
        "                'initial_epoch':0,\n",
        "                'steps_per_epoch':None,\n",
        "                'validation_steps':None}\n",
        "\n",
        "model.fit(X,\n",
        "          y,\n",
        "          epochs = model_params['epochs'],\n",
        "           batch_size = model_params['batch_size'],\n",
        "           callbacks= model_params['callbacks'],\n",
        "           verbose = model_params['verbose'],\n",
        "           validation_split = model_params['validation_split'],\n",
        "           validation_data = model_params['validation_data'],\n",
        "           shuffle = model_params['shuffle'],\n",
        "           initial_epoch = model_params['initial_epoch'],\n",
        "           steps_per_epoch = model_params['steps_per_epoch'],\n",
        "           validation_steps = model_params['validation_steps'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-850b321b93d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m            \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m            \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m            validation_steps = model_params['validation_steps'])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             steps=data_handler.inferred_steps)\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, callbacks, add_history, add_progbar, model, **params)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ModelCheckpoint' object has no attribute '_implements_train_batch_hooks'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AXMqjkkXi7A",
        "colab_type": "text"
      },
      "source": [
        "We can see that some files have been downloaded, we can use such files to load the trained weights to be used in untrained models (i.e we don't have to train a model every time we want to use it) \n",
        "\n",
        "### How to Load the Weights ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sud9lOmYguG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load wights file :\n",
        "wights_file = './models/Weights-LSTM-improvement-004-2.49538-bigger.hdf5' # weights file path\n",
        "model.load_weights(wights_file)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSl6u6oWWFyF",
        "colab_type": "text"
      },
      "source": [
        "Now , after we trained the model ,we can use it to generate fake Taylor Swift lyrics \n",
        "\n",
        "## Generating lyrics \n",
        "We first pick a random seed , then we will use it to generate lyrics character by character ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5EngGk8YuJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set a random seed :\n",
        "start = np.random.randint(0, len(data_X)-1)\n",
        "pattern = data_X[start]\n",
        "print('Seed : ')\n",
        "print(\"\\\"\",''.join([int_chars[value] for value in pattern]), \"\\\"\\n\")\n",
        "\n",
        "# How many characters you want to generate\n",
        "generated_characters = 300\n",
        "\n",
        "# Generate Charachters :\n",
        "for i in range(generated_characters):\n",
        "    x = np.reshape(pattern, ( 1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x,verbose = 0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_chars[index]\n",
        "    #seq_in = [int_chars[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print('\\nDone')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7x2UZ09Z_R5",
        "colab_type": "text"
      },
      "source": [
        "You might noticed that the generated lyrics are not real , and there are many spelling mistakes.\n",
        "\n",
        "You can tweak some parameters and add a Dropout layer to avoid overfitting ,then the model could be better at generating tolerable lyrics.\n",
        "\n",
        "but if you are lazy and don't want to bother yourself trying these steps , try using [textgenrnn](https://goo.gl/E7szXj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nigwY7cRbvoo",
        "colab_type": "text"
      },
      "source": [
        "## Second way : Using [textgenrnn](https://goo.gl/E7szXj)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j00J7LUckAN",
        "colab_type": "text"
      },
      "source": [
        "### Import the dependencies :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15yRfdyNcPCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PL6vHmscxRV",
        "colab_type": "text"
      },
      "source": [
        "### Configure the model :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwLJ4CrfcbNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'rnn_size': 500,\n",
        "    'rnn_layers': 12,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 15,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,\n",
        "    'num_epochs': 100,\n",
        "    'gen_epochs': 25,\n",
        "    'batch_size': 750,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.0,\n",
        "    'max_gen_length': 300,\n",
        "    'validation': True,\n",
        "    'is_csv': False\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR8dJVEWc9D5",
        "colab_type": "text"
      },
      "source": [
        "### Upload the dataset :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wNR9aZYchqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD7mluevdBvl",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xuCgouMdIYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = '500nds_12Lrs_100epchs_Model'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=latest_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKgW9B1Ddcuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(textgen.model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGP6jPhYdegM",
        "colab_type": "text"
      },
      "source": [
        "### Download the trained weights :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY-G1pbgdfDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjU4fA34eVQT",
        "colab_type": "text"
      },
      "source": [
        "### Load trained model and use it :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3ZYCanecNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen = textgenrnn(weights_path='6layers30EpochsModel_weights.hdf5',\n",
        "                       vocab_path='6layers30EpochsModel_vocab.json',\n",
        "                       config_path='6layers30EpochsModel_config.json')\n",
        "\n",
        "generated_characters = 300\n",
        "\n",
        "textgen.generate_samples(300)\n",
        "textgen.generate_to_file('lyrics.txt', 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn_HpyWrnFws",
        "colab_type": "text"
      },
      "source": [
        "Some lyrics generated by a model created using   [textgenrnn](https://goo.gl/E7szXj) :\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "i ' m not your friends\n",
        "and it rains when you ' re not speaking\n",
        "but you think tim mcgraw\n",
        "and i ' m pacing down\n",
        "i ' m comfortable\n",
        "i ' m not a storm in mind\n",
        "you ' re not speaking\n",
        "and i ' m not a saint and i ' m standin ' t know you ' re\n",
        "i ' m wonderstruck\n",
        "and you ' re gay\n",
        "\n",
        "i ' ve been giving out\n",
        "but i ' m just another picture to pay\n",
        "you ' re not asking myself , oh , i ' d go back to december , don ' t know you\n",
        "it ' s killing me like a chalkboard\n",
        "it ' s the one you\n",
        "can ' t you ' re jumping into of you ' re not a last kiss\n",
        "and i ' m just a girl , baby , i ' m alone for me\n",
        "i ' m not a little troubling\n",
        "\n",
        "won ' t you think about a . steps , you roll the stars mind\n",
        "you ' s killing me ? )\n",
        "and i ' m say i won ' t stay beautiful at onto the first page\n",
        "you ' s 2 : pretty\n",
        "and you said real\n",
        "?\n",
        "change makes and oh , who baby , oh , and you talk away\n",
        "and you ' s all a minute , ghosts your arms page\n",
        "these senior making me tough , so hello growing up , we were liar , no one someone perfect day when i came\n",
        "' re not sorry\n",
        "you ' re an innocent\n",
        "on the outskirts\n",
        "\n",
        "ight , don ' t say a house and he ' round\n",
        "she ' re thinking to december all that baby , all everything now\n",
        "and let me when you oh , what to come back my dress\n",
        "always\n",
        "i close both young before\n",
        "at ?\n",
        "yeah\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWBl_cOygt96",
        "colab_type": "text"
      },
      "source": [
        "We saw how easy and convenient it was using  [textgenrnn](https://goo.gl/E7szXj) , yes the lyrics still not realistic, but there are much less spelling mistakes than the model that we built from scratch.\n",
        "\n",
        "another good thing about  [textgenrnn](https://goo.gl/E7szXj) is that one don't have to deal with any dataset processing, just upload the text dataset and set down with a cup of coffee watching your model training and getting better "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgFMQoJ2ikEG",
        "colab_type": "text"
      },
      "source": [
        "## Next Steps :\n",
        "Now, after you learned how to make a LSTM RNN from scratch to generate texts , and also how to use Pyhton modules such as [textgenrnn](https://goo.gl/E7szXj) you can do many things using this knowledge :\n",
        "* Try to use other datasets (wikipedia articles , William Shakespeare novevls, etc) to generate novels or articles.\n",
        "* Use  LSTM RNN in other applications than text generating .\n",
        "* Read more about LSTM RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV3bbXu2quZC",
        "colab_type": "text"
      },
      "source": [
        "## References :\n",
        "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://goo.gl/Kbpk8S)\n",
        "* [Applied Introduction to LSTMs with GPU for text generation](https://goo.gl/xnQSJU)\n",
        "* [Generating Text Using LSTM RNN](https://goo.gl/7GxTxu)\n",
        "* [textgenrnn](https://goo.gl/E7szXj)\n",
        "* [Train a Text-Generating Neural Network for Free with textgenrnn](https://goo.gl/biaFCr)\n",
        "* [Understanding LSTM Networks](https://goo.gl/dgmxQm)\n",
        "* [Long short-term memory](https://en.wikipedia.org/wiki/Long_short-term_memory)"
      ]
    }
  ]
}